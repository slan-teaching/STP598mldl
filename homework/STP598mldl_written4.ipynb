{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rX8mhOLljYeM"
   },
   "source": [
    "# Building CNN for Fashion-MNIST data\n",
    "## STP598 Machine Learning & Deep Learning\n",
    "## Written Assignment 4\n",
    "## Due 11:59pm Friday 11/22/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "04QgGZc9bF5D"
   },
   "source": [
    "In the class, we have [learned CNN for image classification](https://github.com/slan-teaching/STP598mldl/blob/main/demos/lect8_cnn/PT_cifar10_tutorial.ipynb). In this short exerciese, you are asked to build a CNN for the similar classification task using PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nnrWf3PCEzXL"
   },
   "source": [
    "## Set up PyTorch\n",
    "\n",
    "Import PyTorch into your program to get started:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0trJmd6DjqBZ"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7NAbSZiaoJ4z"
   },
   "source": [
    "## Load a dataset\n",
    "\n",
    "Load and prepare the [Fashion MNIST dataset](https://www.kaggle.com/datasets/zalando-research/fashionmnist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7FP5258xjs-v"
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Create datasets for training & validation, download if necessary\n",
    "training_set = torchvision.datasets.FashionMNIST('./data', train=True, transform=transform, download=True)\n",
    "validation_set = torchvision.datasets.FashionMNIST('./data', train=False, transform=transform, download=True)\n",
    "\n",
    "# Create data loaders for our datasets; shuffle for training, not for validation\n",
    "batch_size = 16\n",
    "training_loader = torch.utils.data.DataLoader(training_set, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Class labels\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "# Report split sizes\n",
    "print('Training set has {} instances'.format(len(training_set)))\n",
    "print('Validation set has {} instances'.format(len(validation_set)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a peek at these images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(training_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(16):\n",
    "    plt.subplot(4,4,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(images[i].squeeze(), cmap=\"Greys\")\n",
    "    plt.xlabel(classes[labels[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BPZ68wASog_I"
   },
   "source": [
    "# Build a CNN model\n",
    "\n",
    "1. First, build a 2-layer CNN `model` by stacking `torch.nn.Conv2D` and `torch.nn.MaxPool2D` layers, followed by a `torch.nn.Flatten` and `torch.nn.Linear` with output dimension being 10 (classes). Define the model as a class named `CNNClassifier` inherited from `torch.nn.Module` (note you need to write your own `forward` method)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h3IKyzTCDNGo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l2hiez2eIUz8"
   },
   "source": [
    "2. We use `torch.nn.CrossEntropyLoss` for the loss function, and `adam` for the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9foNKHzTD2Vo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ix4mEL65on-w"
   },
   "source": [
    "## Train and evaluate your model\n",
    "\n",
    "3. In PyTorch, you need to write your own training/validiation loop. Write **training and validation steps** as sepearate functions (each go over trainig/testing dataset once). Then write the **outer loop** with `n_epochs=100` epochs and call the training/validation steps in each epoch. **Remember**: in the training step you need to set `model.train()` and in the validation step you need to set `model.eval()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y7suUbJXVLqP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4mDAAPFqVVgn"
   },
   "source": [
    "4. Record training/testing losses and accuracy. Plot two figures: one for **training/testing losses**, the other for **training/testing accuracy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F7dTAzgHDUh7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "rX8mhOLljYeM"
   ],
   "name": "beginner.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
